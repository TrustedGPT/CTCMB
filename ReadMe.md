# CTCMB ä¸­åŒ»ç»¼åˆè¯„ä¼°åŸºå‡† 

<center>

![Python 3.12](https://img.shields.io/badge/Python-3.12-lightblue) ![Torch 2.3.1](https://img.shields.io/badge/PyTorch-2.3.1-lightblue) ![OpenAi 1.25.0](https://img.shields.io/badge/openai-1.25.0-lightblue) ![bert-score](https://img.shields.io/badge/bert--score-0.3.13-lightblue)
</center>

![title](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/pics/title.jpg)

<p align="center">
   ğŸ“ƒ <a href="" target="_blank">Paper</a> â€¢ ğŸŒ <a href="" target="_blank">Website</a>  
   <br>  <a href="">   ä¸­æ–‡</a> | <a href=""> English
</p>



## ğŸŒˆ æ›´æ–°

- **[2024.Ã—Ã—.Ã—Ã—]** è®ºæ–‡è¢«Ã—Ã—æ¥å—ï¼Œæ„Ÿè°¢å­¦æœ¯ç•Œå¯¹å…¶çš„è®¤å¯ã€‚
- **[2024.Ã—Ã—.Ã—Ã—]** å‘å¸ƒäº†è®ºæ–‡ã€‚
- **[2024.Ã—Ã—.Ã—Ã—]** ğŸ‰ğŸ‰ğŸ‰ CTCMB æ­£å¼å‘å¸ƒï¼ğŸ‰ğŸ‰ğŸ‰
## ğŸŒ æ•°æ®ä¸‹è½½

ï¼ˆ1ï¼‰Zipæ ¼å¼

```python
git clone "https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks.git"&& cd TCM-Assessment-Benchmarks/data
```

ï¼ˆ2ï¼‰[ç™¾åº¦äº‘é“¾æ¥](https://pan.baidu.com/s/1T91QMVJJR7IfkIoL6KCdGA?pwd=3iu2)



## ğŸ“æ’è¡Œæ¦œâ€‹â€‹

| æ¨¡å‹åç§°                   | TCM-ED | TCM-DS | TCM-DID | TCM-FT | TCM-GHGD | Med-Treat | TCM-Clin | TCMeEE | TCM-LitData | TCM-SRT | SPD   | å¹³å‡åˆ† | åæ¬¡ |
| -------------------------- | ------ | ------ | ------- | ------ | -------- | --------- | -------- | ------ | ----------- | ------- | ----- | ------ | ---- |
| ä»²æ€-34b-v1 (ours)         | 86.15  | 83.75  | 59.00   | 72.00  | 54.00    | 50.00     | 92.00    | 84.00  | 72.00       | 99.00   | 57.85 | 73.61  | 1    |
| ERNIE-4.0-8k-Latest        | 72.25  | 68.00  | 54.77   | 72.73  | 60.23    | 59.61     | 68.78    | 59.37  | 71.12       | 88.00   | 48.00 | 65.71  | 2    |
| hunyuan-pro                | 75.50  | 51.00  | 62.63   | 72.06  | 60.41    | 59.54     | 69.52    | 61.08  | 72.35       | 81.00   | 50.00 | 65.01  | 3    |
| step-2-16k-nightly         | 67.00  | 60.00  | 54.49   | 71.79  | 58.60    | 56.07     | 75.67    | 64.22  | 72.99       | 89.00   | 44.00 | 64.89  | 4    |
| qwen2-72b-instruct         | 81.00  | 60.00  | 53.39   | 71.16  | 56.76    | 52.32     | 72.75    | 61.77  | 72.92       | 84.00   | 46.00 | 64.73  | 5    |
| gemini-1.5-pro             | 68.13  | 67.90  | 47.00   | 70.00  | 62.00    | 51.00     | 73.00    | 77.00  | 72.00       | 86.00   | 36.60 | 64.60  | 6    |
| glm-4-0520                 | 71.25  | 54.00  | 56.75   | 72.02  | 60.77    | 52.53     | 68.65    | 60.74  | 69.74       | 93.00   | 41.00 | 63.68  | 7    |
| tiangong                   | 86.00  | 57.00  | 54.34   | 70.35  | 59.37    | 52.81     | 72.63    | 60.58  | 69.49       | 76.00   | 40.00 | 63.51  | 8    |
| SenseChat-5                | 67.75  | 49.00  | 53.28   | 71.39  | 58.57    | 54.82     | 66.95    | 60.83  | 74.36       | 89.00   | 50.00 | 63.27  | 9    |
| Llama-3.1-405b             | 64.25  | 40.00  | 50.98   | 70.77  | 58.28    | 49.36     | 75.92    | 64.42  | 73.97       | 84.00   | 52.00 | 62.18  | 10   |
| 360gpt2-pro                | 75.50  | 40.00  | 57.97   | 71.63  | 55.04    | 51.75     | 68.15    | 60.46  | 73.96       | 81.00   | 48.00 | 62.13  | 11   |
| moonshot-v1-8k             | 59.50  | 51.00  | 46.27   | 71.16  | 61.76    | 49.58     | 75.79    | 62.09  | 70.05       | 90.00   | 36.00 | 61.20  | 12   |
| abab6.5s-chat-pro          | 58.00  | 47.00  | 48.28   | 70.81  | 63.70    | 43.36     | 68.01    | 60.33  | 71.84       | 85.00   | 52.00 | 60.76  | 13   |
| deepseek-chat              | 70.25  | 54.00  | 48.35   | 71.30  | 56.49    | 52.77     | 64.39    | 68.32  | 71.18       | 70.00   | 36.00 | 60.28  | 14   |
| Baichuan4                  | 63.75  | 60.00  | 47.18   | 69.67  | 66.62    | 50.44     | 68.23    | 49.59  | 72.66       | 87.00   | 25.00 | 60.01  | 15   |
| claude-3-5-sonnet-20240620 | 46.75  | 52.00  | 45.87   | 69.56  | 61.74    | 49.80     | 75.36    | 65.07  | 53.88       | 87.00   | 38.00 | 58.64  | 16   |
| gpt-4-turbo-2024-04-09     | 47.25  | 36.00  | 47.21   | 69.50  | 62.23    | 46.31     | 74.67    | 60.42  | 72.68       | 78.00   | 40.00 | 57.66  | 17   |
| Doubao-pro-4k              | 62.75  | 38.00  | 42.23   | 72.52  | 57.16    | 55.78     | 67.15    | 58.51  | 67.53       | 56.00   | 45.00 | 56.60  | 18  |
| mistral-large-latest       | 37.25  | 36.00  | 47.55   | 70.57  | 60.30    | 46.47     | 67.59    | 64.94  | 73.19       | 70.00   | 46.00 | 56.35  | 19   |
| yi-large-turbo             | 53.75  | 38.00  | 50.91   | 70.48  | 56.46    | 48.22     | 66.87    | 57.65  | 60.95       | 68.00   | 45.00 | 56.03  | 20   |
| Spark4.0 Ultra             | 35.25  | 24.00  | 41.02   | 70.43  | 64.43    | 46.22     | 64.08    | 60.49  | 64.82       | 83.00   | 14.00 | 51.61  | 21   |
| Taiyi                      | 42.83  | 17.20  | 47.00   | 68.00  | 42.00    | 45.00     | 61.00    | 53.00  | 71.00       | 58.00   | 3.76  | 46.25  | 22   |
| WiNGPT2-14B-Chat           | 53.60  | 52.00  | 35.00   | 68.00  | 49.00    | 45.00     | 64.00    | 57.00  | 58.00       | 21.00   | 2.06  | 45.88  | 23   |
| HuatuoGPT2-34B             | 29.30  | 25.80  | 39.00   | 67.00  | 55.00    | 25.00     | 64.00    | 60.00  | 58.00       | 45.00   | 1.00  | 42.65  | 24   |

## ğŸ˜Šæ•°æ®é›†æè¿°

![pie-nest](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/pics/pie-nest.png)

#### ç»“æ„

æ•°æ®é›†ï¼š**5**ä¸ªç±»åˆ«ï¼Œ**12**ä¸ªæ•°æ®é›†

5ä¸ªç±»åˆ«ï¼ˆæ¯ä¸ªç±»åˆ«åŒ…å«1-3ä¸ªæ•°æ®é›†ï¼‰

- ä¸­åŒ»çŸ¥è¯†é—®ç­”ï¼šä»¥é€‰æ‹©ã€åˆ¤æ–­å’Œé—®ç­”å½¢å¼è€ƒæ ¸ä¸­åŒ»åŸºç¡€ã€‚
- åŒ»å­¦è¯­è¨€ç”Ÿæˆï¼šè¯„ä¼°æ¨¡å‹ç”Ÿæˆæ ‡å‡†åŒ»å­¦æ–‡æœ¬çš„èƒ½åŠ›ã€‚
- ä¸­åŒ»æ¨ç†ï¼šè¯„ä¼°æ¨¡å‹åŸºäºä¸­åŒ»ç†è®ºçš„æ¨ç†èƒ½åŠ›ã€‚
- ä¸­åŒ»è¯­è¨€ç†è§£ï¼šè¯„ä¼°æ¨¡å‹å¯¹ä¸­åŒ»ä¸“ä¸šè¯­è¨€çš„ç†è§£ã€‚
- ä¸­åŒ»è¯Šæ–­ï¼šè¯„ä¼°æ¨¡å‹è¿ç”¨å››è¯Šåˆå‚çš„è¯Šæ–­èƒ½åŠ›ã€‚

TCM-ED  TCM-DS  TCM-SRT ä¸ºå®¢è§‚é¢˜,å…¶ä½™ä¸ºä¸»è§‚é¢˜ï¼Œå…¶ä¸­TCM-EDåŒ…å«Aå‹é¢˜ï¼ˆæœ€ä½³é€‰æ‹©é¢˜ï¼‰ã€Bå‹é¢˜ï¼ˆç—…å†æ‘˜è¦å‹æœ€ä½³é€‰æ‹©é¢˜ï¼‰ã€Cå‹é¢˜ï¼ˆå…±ç”¨é¢˜å¹²é€‰æ‹©é¢˜ï¼‰ä»¥åŠDå‹é¢˜ï¼ˆå…±ç”¨é€‰é¡¹é€‰æ‹©é¢˜ï¼‰ã€‚

#### è¯¦ç»†ä¿¡æ¯

**ç‚¹å‡»è¶…é“¾æ¥å¯ä»¥æŸ¥çœ‹åˆ°ä¸åŒæ•°æ®é›†æ ¼å¼è¦æ±‚**â¬…ï¸â¬…ï¸

| ä¸€çº§ç›®å½•     | äºŒçº§ç›®å½•                                                     | æ•°é‡ | æ•°æ®æ¥æº                                                     | è¯„ä¼°æ–¹æ³•                             |
| :----------- | ------------------------------------------------------------ | ---- | ------------------------------------------------------------ | ------------------------------------ |
| ä¸­åŒ»çŸ¥è¯†é—®ç­” | TCM-EDï¼ˆ[A](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/A_problem.md)ã€[B](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/B_problem.md)ã€[C](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/C_problem.md)ã€[D](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/D_problem.md)ï¼‰ | 720  | ACDæ¥è‡ªä¸­åŒ»ä¸»æ²»åŒ»å¸ˆè€ƒæ ¸å’ŒèŒä¸šåŒ»å¸ˆè€ƒæ ¸ï¼ŒBæ˜¯GPTç”Ÿæˆ            | Accuracy                             |
|              | [TCM-DID](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/3.TCM-DID%20Dataset.md) | 100  | ã€Šä¸­åŒ»åŸºç¡€ç†è®ºä¹ é¢˜é›†ã€‹ä¸»ç¼–éƒ‘æ´ªæ–°                             | ä½¿ç”¨BERTScoing                       |
|              | [TCM-FT](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/4.TCM-FT.md)                                                      | 100  | ã€Šä¸­åŒ»å­¦é—®ç­”é¢˜åº“ã€‹èƒ¡ç†™æ˜ä¸»ç¼–                                 | ä½¿ç”¨BERTScoing                       |
| åŒ»å­¦è¯­è¨€ç”Ÿæˆ | [TCMeEE](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/8.TCMeEE.md) | 100  | åŸå§‹æ•°æ®æ˜¯[zhongyigen.com](https://zhongyigen.com/)çš„åŒ»æ¡ˆï¼Œåˆ©ç”¨GPTè¿›è¡Œå®ä½“æŠ½å–ï¼Œç”Ÿæˆè€Œæ¥çš„ã€‚ | é‡‡ç”¨BERTScoring,ROUGE,BLEUå¹³å‡çš„æ–¹å¼ |
|              | [SCD](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/11.SCD.md) | 100  | ä½¿ç”¨åŒ»æ¡ˆç”Ÿæˆç—…å†æ•°æ®ï¼Œç„¶åå†å°†ç—…ä¾‹è¿›è¡Œåˆ‡åˆ†ï¼Œåˆ‡åˆ†åçš„ç—…ä¾‹åˆ†åˆ«ç”¨äºç”ŸæˆåŸå¯¹è¯å’Œè¡¥å……å¯¹è¯ï¼Œå†åˆ©ç”¨åŸå¯¹è¯ç”ŸæˆåŸå§‹çš„ç°ç—…å²å’Œæ—¢å¾€å²ï¼Œå°†æœªåˆ‡åˆ†çš„ç—…ä¾‹ä½œä¸ºè°ƒä¼˜çš„ç°ç—…å²å’Œæ—¢å¾€å²ã€‚ | LLMè¯„ä¼°                              |
|              | [TCM-CHGD](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/5.TCM-CHGD.md) | 100  | ä¸­åŒ»æ™ºåº“çš„åŒ»æ¡ˆè½¬åŒ–æˆçš„å¯¹è¯æ•°æ®ï¼Œç»gptè½¬åŒ–ç”Ÿæˆç—…ä¾‹            | é‡‡ç”¨BERTScoring,ROUGE,BLEUå¹³å‡çš„æ–¹å¼ |
| ä¸­åŒ»æ¨ç†     | [TCM-SRT](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/10.TCM-SRT.md) | 100  | æ¥è‡ª[CCKS2024-TCMBench](https://tianchi.aliyun.com/competition/entrance/532204label)ä¸­åŒ»çŸ¥è¯†ç†è§£ä¸æ¨ç†èƒ½åŠ›è¯„æµ‹ä¸­ä»»åŠ¡äºŒçš„æ•°æ®ã€‚ | Accuracy                             |
|              | [SPD](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/12.SPD.md) | 100  | GPTç”Ÿæˆç»“åˆã€Šä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­-ç¬¬2éƒ¨åˆ†ï¼šè¯å€™ã€‹çš„æ•°æ®ç”Ÿæˆç”Ÿæˆè€Œæ¥ | Top-kæ–¹æ³•                            |
| ä¸­åŒ»è¯­è¨€ç†è§£ | [TCM-LitData](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/9.TCM-LitData.md) | 100  | æ¥è‡ª[ç½‘ç«™](https://tianchi.aliyun.com/dataset/86895)çš„ä¸­åŒ»æ–‡çŒ®é—®é¢˜ç”Ÿæˆæ•°æ®é›†ã€‚ | é‡‡ç”¨BERTScoring,ROUGE,BLEUå¹³å‡çš„æ–¹å¼ |
| ä¸­åŒ»è¯Šæ–­     | [Med-Treat](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/6.Med-Treat.md) | 100  | ä»ä¸­åŒ»æ–¹å‰‚ç½‘çˆ¬å–çš„æ•°æ®è½¬åŒ–è€Œæ¥ã€‚                             | é‡‡ç”¨BERTScoring,ROUGE,BLEUå¹³å‡çš„æ–¹å¼ |
|              | [TCM-Clin](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/7.TCM-Clin.md) | 100  | [A Benchmark for Probing Syndrome Differentiation via Natural Language Processing](https://arxiv.org/abs/2203.10839) æ–‡ç« çš„æ•°æ®ã€‚ | ä½¿ç”¨BERTScoing                       |
|              | [TCM-DS](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/dataset_info/2.TCM-DS%20Dataset.md) | 200  | GPTæ ¹æ®ã€Šä¸­åŒ»ä¸´åºŠè¯Šç–—æœ¯è¯­-ç¬¬2éƒ¨åˆ†ï¼šè¯å€™ã€‹ä¸­å¯¹ç–¾ç—…çš„æè¿°ç”Ÿæˆã€‚ | Accuracy                             |





## ğŸ”†å¦‚ä½•æäº¤å’Œè¯„ä¼°

### ç¯å¢ƒé…ç½®


ç¡®ä¿ä½ çš„å¼€å‘ç¯å¢ƒå·²ç»å®‰è£…äº†[æ–‡ä»¶](https://github.com/Wayyuanyuan/TCM-Assessment-Benchmarks/blob/main/requirements.txt)è¦æ±‚çš„Pythonåº“





### é—®ç­”æ¨¡å—

ç›®å‰æä¾›åŸºäºOpenAIåº“çš„è°ƒç”¨æ¨¡ç‰ˆï¼Œå¹¶ä¸”æä¾›ä¸‰å¥—HuggingFaceä¸Šå¼€æºåº“çš„è°ƒç”¨æ¨¡ç‰ˆï¼Œåˆ†åˆ«æ˜¯`HuatuoGPT-II`ï¼Œ`Taiyi-LLM`å’Œ`WiNGPT2`è°ƒç”¨ã€‚å¦‚æœéœ€è¦å…¶ä»–æ›´å¤šè°ƒç”¨çš„æ”¯æŒï¼Œè¯·ç»§æ‰¿è‡ª`make_answer/chat/chat_invoker.py`æ¨¡å—ä¸­çš„`ChatInvoker`æ¥å£ã€‚

#### åŸºäºOpenAIåº“çš„è°ƒç”¨æ¨¡ç‰ˆ

`æ¨¡å—å.è°ƒç”¨llmæ–‡ä»¶`.py


```python
import os
import openai

from loguru import logger
from make_answer.chat.chat_invoker import ChatInvoker


class LlmOpenai(ChatInvoker):
    def __init__(self, *args, **kwargs):
        base_url = os.environ.get("OPENAI_BASE_URL")
        if "base_url" in kwargs:
            base_url = kwargs["base_url"]
        api_key = os.environ.get("OPENAI_API_KEY")
        if "api_key" in kwargs:
            api_key = kwargs["api_key"]
        self.client = openai.OpenAI(
            base_url=base_url, api_key=api_key)
        self.model_name = kwargs["model_name"]

    def chat(self, msg: str, *args, **kwargs) -> str:
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šä¸­åŒ»åŒ»ç”Ÿï¼Œèƒ½å¤Ÿå‡†ç¡®å…¨é¢çš„è§£ç­”ä¸­åŒ»é—®é¢˜ã€‚æœ¬æ¬¡å¯¹è¯ï¼Œå‡åªé‡‡ç”¨ä¸­æ–‡æé—®å’Œå›ç­”ã€‚"},
                {"role": "user", "content": msg}
            ]
        )
        try:
            ret = response.choices[0].message.content
        except Exception as e:
            logger.exception(f"call openai chat api error: {response}")
            raise e

        return ret
```

##### ä½¿ç”¨æ–¹å¼

```python
python main.py \
--step-chat data/ \ # æµ‹è¯•é—®é¢˜æ‰€åœ¨æ–‡ä»¶å¤¹
--api-model æ¨¡å—å.è°ƒç”¨llmæ–‡ä»¶.ç±»å \ # è‡ªå®šä¹‰æµ‹è¯•æ¨¡å‹ï¼Œéœ€è¦ç»§æ‰¿è‡ªChatInvokerï¼Œä¼ å…¥å®Œæ•´æ¨¡å—åã€æ–‡ä»¶åå’Œç±»å
--api-model-name è°ƒç”¨çš„å¤§æ¨¡å‹åç§° \ # å¤§æ¨¡å‹åç§°ï¼Œç”¨äºåŒºåˆ†è°ƒç”¨çš„ä¸åŒæ¨¡å‹ï¼Œä»¥åŠä¸åŒæ¨¡å‹ç»“æœ
--base-url æ¨¡å‹è°ƒç”¨url \ # æ¨¡å‹url
--api-key æ¨¡å‹key  # è°ƒç”¨æ¨¡å‹key
```

##### åŸºäºOpenAIåº“çš„è°ƒç”¨ç¤ºä¾‹

```
python main.py --step-chat data --api-model make_answer.chat.remote.openai_api.LlmOpenai --llm-name your_model_name  --base-url your_url --api-key yourâ€”â€”key --num-process 12
```



#### åŸºäºæœ¬åœ°è°ƒç”¨å½¢å¼

`æ¨¡å—å.è°ƒç”¨llmæ–‡ä»¶`.py

```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

from make_answer.chat.chat_invoker import ChatInvoker


class LocalLLM(ChatInvoker):
    def __init__(self, model_path: str, gpu_id: int = 0):
        # æ¨¡å‹åˆå§‹åŒ–ï¼Œä»…åœ¨é¦–æ¬¡è¿è¡Œæ—¶æ‰§è¡Œã€‚

    def chat(
            self, msg: str, *args, **kwargs
    ) -> str:
        # è¯·æ±‚æ¨¡å‹å›ç­”ï¼Œmsgä¸ºå¿…å¡«å‚æ•°ã€‚
```

##### ä½¿ç”¨æ–¹å¼

```python
python main.py \
--step-chat data/ \ # æµ‹è¯•é—®é¢˜æ‰€åœ¨æ–‡ä»¶å¤¹
--local-model /Path/To/LLM \ # æœ¬åœ°å¤§æ¨¡å‹æ‰€åœ¨ç›®å½•
--chat-func-name LLMåç§° # å¤§æ¨¡å‹åç§°ï¼Œéœ€è¦å°†è‡ªå®šæ¨¡ç‰ˆæ„é€ å‡½æ•°å†™åœ¨ï¼šmake_answer/chat/__init__.pyçš„name_model_dictä¸­ã€‚
```



### è¯„ä¼°æ¨¡å—

ä½¿ç”¨æ–¹å¼

```python
python main.py \
--step-evaluate LLMå›ç­”æ‰€åœ¨ç›®å½• \ # ä¸€èˆ¬æƒ…å†µä¸‹ï¼Œ ä¼ å…¥æ ¹ç›®å½•ä¸‹æ¨¡å‹åç§°
--standard-answer-root æ ‡å‡†ç­”æ¡ˆç›®å½• # ä¼ å…¥æ ‡å‡†ç­”æ¡ˆç›®å½•
```



### å…¶ä»–å‚æ•°

 

| å‚æ•°åç§°      | é»˜è®¤å€¼ | ä½œç”¨                               |
| ------------- | ------ | ---------------------------------- |
| --num-process | 1      | è°ƒç”¨å¤§æ¨¡å‹å›ç­”ä»¥åŠè¯„ä¼°æ—¶å¹¶å‘çº¿ç¨‹æ•° |
| --sleep-time  | 0      | å¤§æ¨¡å‹å•æ¬¡å›ç­”åï¼Œç­‰å¾…çš„æ—¶é—´ã€‚     |





## è‡´è°¢


æˆ‘ä»¬è¡·å¿ƒæ„Ÿè°¢Ã—Ã—Ã—å¯¹æœ¬é¡¹ç›®çš„å·¨å¤§æ”¯æŒã€‚ğŸ‰ğŸ‰ğŸ‰

åŒæ—¶ï¼Œæ„Ÿè°¢å‚ä¸æœ¬é¡¹ç›®çš„å…¨ä½“æˆå‘˜ï¼


